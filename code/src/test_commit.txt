OpenShift (overview)
OpenShift, developed by Red Hat, is like a large scale Kubernetes platform that provides additional tools and services to manage containerized apps. It builds on Kubernetes with added capabilities 
Benefits: streamline app development and deployment, Integrates with tools like Jenkins or Harness for CI/CD, native Kubernetes orchestration with added layers, auto-scaling, self-healing, etc.

So the OCP website portal provides many features and components that define the deployment process. Here were my takeaways from my observations of different components- 
1. Projects: (similar to namespaces in Kubernetes) projects are like the primary organizational unit for deployment in Openshift. Each project isolates resources (deployments, services, pods, etc.) and provides RBAC (Role-Based Access Control) boundaries.
2. Builds: The build process converts source code into a container objects (container images in openshift). There is 1 main things to look for here - BuildConfig helps define the strategy (how docker build, source code to image) and triggers
Workflow that goes: Code commit → Trigger BuildConfig → Generate image.
3. The Inventory section (also deployment mechanisms)
Deployments/DeploymentConfigs:
Deployment: Kubernetes-native way of managing stateless applications.
DeploymentConfig (DC): OpenShift-specific abstraction providing advanced deployment strategies. Basically deployment configurations and the application rollout details.
Pods: Displays the current running instances, including details on their status, health, and resource usage. They are the running instances of your containerized app. The smallest deployable units that run your containerized applications.
Services: Provide stable networking endpoints for accessing pods. They have internal load balancing endpoints.
Routes: Expose services externally, handling HTTP/HTTPS traffic. External access points.
Builds: Shows active and past build processes (using BuildConfigs and ImageStreams).
ConfigMaps & Secrets: Presents configuration data and sensitive information used by your applications.

Each resource has detailed views for logs, events, and underlying YAML/JSON configurations.
3. End-to-End Deployment Process with Harness Integration
Harness is a modern Continuous Delivery (CD) platform that automates deployments across Kubernetes environments, including OpenShift. 
Step 1: Set Up Your OCP Environment:
Step 2: Building the Application
Configure BuildConfig in OpenShift:
Define a BuildConfig that specifies the build strategy (S2I or Docker).
Example using S2I:
yaml
CopyEdit
apiVersion: build.openshift.io/v1
kind: BuildConfig
metadata:
  name: my-microapp-build
spec:
  source:
    git:
      uri: 'https://github.com/your-repo.git'
  strategy:
    sourceStrategy:
      from:
        kind: ImageStreamTag
        name: 'nodejs:14'  # or your base image
Triggers: Configure webhooks to trigger builds upon code commits.
Step 3: Deployment Pipeline in Harness
Connect Harness to Your OCP Cluster:
In Harness, add your OpenShift cluster credentials (API endpoint, token, certificate) as a deployment target.
Set up a connector that maps to your project/namespace in OpenShift.
Create a Pipeline:
Build Stage:
Integrate your repository and trigger the build process.
Harness can kick off an OpenShift build via API calls or webhooks.
Deployment Stage:
Configure the deployment step that tells Harness how to deploy your image.
Leverage Kubernetes manifest deployment templates that point to your DeploymentConfig.
Configure parameters (e.g., replica count, environment variables from ConfigMaps and Secrets).
Pipeline Execution:
When the pipeline runs, Harness instructs OpenShift to:
Pull the latest image (from ImageStream).
Update the DeploymentConfig.
Initiate a new rollout.
Harness can continuously monitor for issues and automatically roll back if health checks fail.
Step 4: Behind the Scenes – What Happens in OpenShift
Image Deployment:
The new image is scheduled into a pod, and OpenShift’s scheduler places it on a node.
Service and Route Configuration:
The Service ensures that pods are grouped, providing a stable endpoint.
The Route exposes the Service externally.
Rollout Process:
The DeploymentConfig initiates a rolling update. It creates new pods while phasing out the old ones, maintaining service availability.
Resource Updates:
ConfigMaps and Secrets are mounted into pods as environment variables or volumes. Changes to these can trigger pod restarts if configured.
Step 5: Debugging and Monitoring
Using the OpenShift Console:
Inventory Views:
Monitor pods, deployments, and events.
Drill down on any pod to see container logs, resource usage, and event history.
Log Aggregation:
Utilize the integrated logging stack (Elasticsearch, Fluentd, Kibana) if set up.
Harness Feedback:
Harness dashboards show deployment status, success metrics, and alerts..
Step 6: Debugging
Debugging Failed Builds: Check Build logs, Inspect build pods for errors.
Environment-Specific Configurations: Verify that environment variables are correctly injected in pods by checking the pod's configuration.

4. Practical Sections of the OCP Portal
When you log in to the OCP web console, you’ll encounter various sections:
Dashboard: Overview of your projects and resource usage.
Projects: A list of namespaces with a summary of each project’s resource statuses.
Builds: Detailed view of BuildConfigs, build histories, and logs.
Applications/Workloads: Contains Deployments, DeploymentConfigs, ReplicaSets, and Pods.
Networking: Includes Services and Routes for exposing your applications.
Storage: Manages persistent volumes and claims.
Resources: Displays ConfigMaps, Secrets, and other ancillary resources.
Monitoring & Logging (if enabled): Provides integrated performance metrics and logs for troubleshooting.












3. The Deployment Pipeline and Harness Integration
Integrating OpenShift with Harness enables automated, reliable application deployments. Here’s a breakdown of the process:
A. Preparation and Setup
OCP Environment:
Created a dedicated project using oc new-project my-microapp to isolate our application resources.
Configured the oc CLI and ensured proper credentials for interacting with the cluster.
Source Code Management:
Structured the repository to include necessary Dockerfiles or S2I configurations, ensuring that both microfrontends and backend services are container-ready.
B. Building the Application
BuildConfig Definition:
Configured a BuildConfig YAML that triggers on code commits and uses S2I to build our container images.
Example snippet:
yaml
CopyEdit
apiVersion: build.openshift.io/v1
kind: BuildConfig
metadata:
  name: my-microapp-build
spec:
  source:
    git:
      uri: 'https://github.com/your-repo.git'
  strategy:
    sourceStrategy:
      from:
        kind: ImageStreamTag
        name: 'nodejs:14'


ImageStream Integration:
Updated ImageStreams track image versions, ensuring that deployments always use the latest verified image.
C. Continuous Deployment with Harness
Cluster Connection:
In Harness, I connected our OpenShift cluster using the appropriate API endpoint, authentication tokens, and certificates.
Pipeline Creation:
Build Stage: Initiated builds through Harness, which triggered the BuildConfig in OpenShift.
Deployment Stage: Configured deployment steps in Harness to update DeploymentConfigs with the new image, managing parameters like replica count and environment variables.
Verification Stage: Set up health checks and automated tests. Harness monitored the rollout, ensuring successful deployment before marking the process complete.
Behind the Scenes:
Harness instructs OpenShift to schedule the new pods using the latest image. OpenShift’s scheduler places the pods on available nodes, while Services and Routes ensure that the updated application is accessible.
The DeploymentConfig orchestrates a rolling update, replacing old pods gradually to maintain application availability.
4. Debugging, Monitoring, and Best Practices
Ensuring that deployments are successful and troubleshooting any issues quickly is paramount. Here’s what I learned:
A. Debugging and Logs
The Inventory view provides detailed insights into all project resources including deployments, pods, services, and routes.
Each resource has an option to view logs and events, which is critical for pinpointing issues during deployment.
B. Pipeline Debugging in Harness
Harness dashboards display the progress of deployments in real time, including success metrics and failure alerts.
Automated rollback procedures in Harness ensure that if a new deployment fails health checks, the system reverts to the previous stable version.
